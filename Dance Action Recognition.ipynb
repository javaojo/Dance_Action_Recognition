{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0381a5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorflow) (57.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from matplotlib) (4.31.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from matplotlib) (1.4.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\joseph\\pycharmprojects\\finalyearproject\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Joseph\\PycharmProjects\\FinalYearProject\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python mediapipe sklearn matplotlib thefuzz pyttsx3 pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44e5ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from thefuzz import fuzz\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cffb4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic  # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing utilities\n",
    "\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False  # Image is no longer writeable\n",
    "    results = model.process(image)  # Make prediction\n",
    "    image.flags.writeable = True  # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)  # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks,\n",
    "                              mp_holistic.HAND_CONNECTIONS)  # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks,\n",
    "                              mp_holistic.HAND_CONNECTIONS)  # Draw right hand connections\n",
    "\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                              mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in\n",
    "                     results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in\n",
    "                   results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in\n",
    "                   results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(\n",
    "        21 * 3)\n",
    "    return np.concatenate([pose, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f4b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.video_dataset = self.generate_dataset()\n",
    "        self.number_of_videos = 30\n",
    "        self.number_of_frames = 30\n",
    "        self.path = os.path.join('EXTRACTION')\n",
    "        \n",
    "    def update_dataset_collection(self, new_dataset):\n",
    "\n",
    "        self.video_dataset = self.video_dataset | new_dataset\n",
    "        \n",
    "    def get_video_dataset(self):\n",
    "        return self.video_dataset\n",
    "\n",
    "    def get_videos(self, video_query):\n",
    "        for video_category in self.video_dataset:\n",
    "            if video_query == video_category:\n",
    "                return self.video_dataset[video_query]\n",
    "\n",
    "    def get_video_sequence_length(self, video):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        total_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        return total_frame_count\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        directory = \"DATASET\"\n",
    "\n",
    "        # create a dictionary\n",
    "        # to store video directory and the amount of frames of each video\n",
    "        videos_array = dict()\n",
    "\n",
    "        for filename in os.listdir(directory):\n",
    "\n",
    "            file = os.path.join(directory, filename)\n",
    "\n",
    "            # Store the name of each dance at the start of the dictionary\n",
    "            videos_array[filename] = []\n",
    "\n",
    "            for video_filename in os.listdir(file):\n",
    "                video_dict = dict()\n",
    "\n",
    "                # Gets specified video file directory\n",
    "                video_file = os.path.join(file, video_filename)\n",
    "\n",
    "                video_dict['File'] = video_file\n",
    "                \n",
    "                # Get frame length of each video\n",
    "                video_dict['Frames'] = self.get_video_sequence_length(video_file)\n",
    "\n",
    "                # Store frame length to each respect individual video\n",
    "                videos_array[filename].append(video_dict)\n",
    "\n",
    "                # Create an action array to store numpy data\n",
    "        actions = np.array(list(videos_array))\n",
    "        return videos_array\n",
    "\n",
    "    \n",
    "    def directory_to_store_video_keypoints(self):\n",
    "\n",
    "        for dance in list(self.video_dataset):\n",
    "            number_of_videos = len(self.video_dataset[dance])\n",
    "            for dictionary in self.video_dataset[dance]:\n",
    "                for video_number in range(self.number_of_videos):\n",
    "                    try:\n",
    "                        os.makedirs(os.path.join(self.path, dance, str(video_number)))\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    def collect_video_keypoints(self):\n",
    "        \"\"\"This will allow a user to capture new movements from a video for the program to then\n",
    "        collect the new keypoints as npy file to then train the model\"\"\"\n",
    "        \n",
    "        self.directory_to_store_video_keypoints()\n",
    "\n",
    "        for dance in list(self.video_dataset):\n",
    "            current_video = -1\n",
    "\n",
    "            # Loop through all videos of dance\n",
    "            for dictionary in self.video_dataset[dance]:\n",
    "\n",
    "                video = dictionary['File']\n",
    "                \n",
    "                current_video += 1\n",
    "                print(\"this is video file: \" + video)\n",
    "\n",
    "                cap = cv2.VideoCapture(video)\n",
    "\n",
    "                # Set mediapipe model\n",
    "                with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "                    print(\"this is video number: \" + str(current_video))\n",
    "\n",
    "                    # Loop through video length aka sequence length\n",
    "                    for frame_num in range(self.number_of_frames):\n",
    "\n",
    "                        # Read feed\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret:\n",
    "\n",
    "                            print(\"Ignoring empty camera frame.\")\n",
    "                            break\n",
    "                        else:\n",
    "                            # Make detections\n",
    "                            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                            # Draw landmarks\n",
    "                            draw_styled_landmarks(image, results)\n",
    "\n",
    "                            # NEW Apply wait logic\n",
    "                            if frame_num == 0:\n",
    "                                cv2.putText(image, 'STARTING COLLECTION', (120, 200),\n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(dance, current_video),\n",
    "                                            (15, 12),\n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                                # Show to screen\n",
    "                                cv2.imshow('OpenCV Feed', image)\n",
    "                                cv2.waitKey(2000)\n",
    "                            else:\n",
    "                                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(dance, current_video),\n",
    "                                            (15, 12),\n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                                # Show to screen\n",
    "                                cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                            # NEW Export keypoints\n",
    "                            keypoints = extract_keypoints(results)\n",
    "                            npy_path = os.path.join(self.path, dance, str(current_video), str(frame_num))\n",
    "                            np.save(npy_path, keypoints)\n",
    "\n",
    "                            # Break gracefully\n",
    "                            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                                break\n",
    "\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab63b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordVideo(Video):\n",
    "\n",
    "    def __init__(self, new_action_list):\n",
    "        \"\"\"new_action_list must be an array\"\"\"\n",
    "        super().__init__()\n",
    "        # Thirty videos worth of data\n",
    "        self.no_sequences = 1\n",
    "        # Videos are going to be 30 frames in length\n",
    "        self.sequence_length = 30\n",
    "        # Directory where videos are being stored\n",
    "        self.PATH = os.path.join('DATASET')\n",
    "        # initialize Text-to-speech engine\n",
    "        self.engine = pyttsx3.init()\n",
    "\n",
    "        self.new_actions = new_action_list\n",
    "\n",
    "    def text_to_speech(self, text):\n",
    "        \"\"\"Convert text into speech\"\"\"\n",
    "        self.engine.say(text)\n",
    "\n",
    "        # play the speech\n",
    "        self.engine.runAndWait()\n",
    "\n",
    "    def make_video_src_directory(self, actions_list):\n",
    "        \"\"\"Create a directory for the new action being captured\"\"\"\n",
    "        for action in actions_list:\n",
    "            try:\n",
    "                os.makedirs(os.path.join(self.PATH, action))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def capture_new_dance_action(self):\n",
    "        \"\"\"Record the new action 30 times and store it in the respective folder\"\"\"  \n",
    "        self.make_video_src_directory(self.new_actions)\n",
    "        temp_string = \"\"\n",
    "        action_dictionary = dict()\n",
    "        video_set_array = []\n",
    "        \n",
    "        for dance_action in self.new_actions:\n",
    "            \n",
    "            temp_string = dance_action\n",
    "                        \n",
    "            n = 0\n",
    "            print(\"Capturing Dance Videos For: \" + dance_action)\n",
    "            self.text_to_speech(\"Capturing Dance Videos For: \" + dance_action)\n",
    "            for i in range(self.no_sequences):\n",
    "\n",
    "                # The duration in seconds of the video captured\n",
    "\n",
    "                print(\"Capturing \" + dance_action + \" Video Number: \"  + str(n+1))\n",
    "                self.text_to_speech(\"Video Number: \" + str(n+1))\n",
    "                \n",
    "                individual_video_dictionary = dict()\n",
    "                \n",
    "                \n",
    "                capture_duration = 4\n",
    "\n",
    "                cap = cv2.VideoCapture(1)\n",
    "\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "                if n <= 9:\n",
    "                    name = dance_action + \"_\" + \"00\" + str(n) + \".mp4\"\n",
    "\n",
    "                elif 99 >= n > 9:\n",
    "                    name = dance_action + \"_\" + \"0\" + str(n) + \".mp4\"\n",
    "                else:\n",
    "                    name = dance_action + \"_\" + str(n) + \".mp4\"\n",
    "\n",
    "                \n",
    "                mp4_path = os.path.join(self.PATH, dance_action, name)\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "                print(mp4_path)\n",
    "                out = cv2.VideoWriter(mp4_path, fourcc, 30.0, (width, height), isColor=True)\n",
    "                n += 1\n",
    "                start_time = time.time()\n",
    "                self.text_to_speech(\"Starting Recording\")\n",
    "                while int(time.time() - start_time) < capture_duration:\n",
    "\n",
    "                    ret, frame = cap.read()\n",
    "                    if ret:\n",
    "\n",
    "                        out.write(frame)\n",
    "                        cv2.putText(frame, 'COLLECTING DATASET', (120, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                        cv2.putText(frame, 'Collecting frames for {} Video Number {}'.format(dance_action, n),\n",
    "                                    (15, 12),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        cv2.imshow('frame', frame)\n",
    "\n",
    "                        key = cv2.waitKey(1)\n",
    "                        if key == ord('q'):\n",
    "                            break\n",
    "                        if key == ord('p'):\n",
    "                            cv2.waitKey(-1)  # wait until any key is pressed\n",
    "\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                \n",
    "                individual_video_dictionary['File'] = mp4_path\n",
    "                individual_video_dictionary['Frames'] = 0\n",
    "                \n",
    "                video_set_array.append(individual_video_dictionary)\n",
    "                \n",
    "                \n",
    "                self.text_to_speech(\"Stop Recording\")\n",
    "    \n",
    "                \n",
    "                cap.release()\n",
    "                out.release()\n",
    "                cv2.destroyAllWindows()\n",
    "        action_dictionary[temp_string] = video_set_array\n",
    "        self.text_to_speech(\"All Recordings Complete. Have a great day!\")\n",
    "        \n",
    "        return action_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e57efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Video):\n",
    "\n",
    "    def __init__(self, video):\n",
    "        super().__init__()\n",
    "        \n",
    "        # pass in object video\n",
    "        self.video = video\n",
    "        \n",
    "        # Store action collection\n",
    "        self.actions = np.array(sorted(video.get_video_dataset()))\n",
    "    \n",
    "    def get_video(self):\n",
    "        return self.video\n",
    "    \n",
    "    def get_actions(self):\n",
    "        return self.actions\n",
    "    \n",
    "    def search_action(self, query):\n",
    "        for action in self.actions:\n",
    "            if query == action:\n",
    "                return action\n",
    "        return None\n",
    "\n",
    "    def add_new_action(self):\n",
    "        \n",
    "        print(\"We will need to capture this action 30 times\\n\")\n",
    "        print(\"Enter q to quit\\n\")\n",
    "        print(\"Make sure the name of action is at least  3 characters\\n\")\n",
    "        x = True\n",
    "        while x:\n",
    "\n",
    "            new_action = str(input('Enter the name of your dance action, the action has to be short to be captured: '))\n",
    "\n",
    "            if new_action == \"q\" or new_action == \"Q\":\n",
    "                print(\"Process terminated\")\n",
    "                return None\n",
    "\n",
    "            elif len(new_action) < 3:\n",
    "                print(\"The action name must be longer at least 3 characters.\\n\") \n",
    "\n",
    "            elif new_action in self.actions:\n",
    "                print(\"Unfortunately an action of this name already exists.\\n\")\n",
    "            else:\n",
    "                x = False\n",
    "\n",
    "        print(\"Action about to be captured\")\n",
    "        \n",
    "        self.actions= np.append(self.actions, new_action)\n",
    "        \n",
    "        new_action_dataset = RecordVideo([new_action]).capture_new_dance_action()\n",
    "        \n",
    "        self.video.update_dataset_collection(new_action_dataset)\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8701f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModel(Action):\n",
    "    \n",
    "    \n",
    "    def __init__(self, action):\n",
    "        \n",
    "        # this is the number of frames we are using from a video\n",
    "        self.sequence_length = 30\n",
    "        self.path = os.path.join('EXTRACTION')\n",
    "        \n",
    "        # action is an object\n",
    "        # actions is a list\n",
    "        self.actions = action.actions\n",
    "        \n",
    "        self.log_dir = os.path.join('Logs')\n",
    "        self.tb_callback = TensorBoard(log_dir=self.log_dir)\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 258)))\n",
    "        self.model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "        self.model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "        self.model.add(Dense(64, activation='relu'))\n",
    "        self.model.add(Dense(32, activation='relu'))\n",
    "        self.model.add(Dense(self.actions.shape[0], activation='softmax'))\n",
    "        self.model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "        \n",
    "        \n",
    "    def set_model(self, load):\n",
    "        X_train, X_test, y_train, y_test = self.train()\n",
    "\n",
    "        if load == False:\n",
    "            self.model.fit(X_train, y_train, epochs=80, callbacks=[self.tb_callback])\n",
    "            self.model.save('DTHOT_3.h5')\n",
    "\n",
    "        else:\n",
    "            self.model.fit(X_train, y_train, epochs=0, callbacks=[self.tb_callback])\n",
    "            self.model.load_weights('DTHOT.h5')\n",
    "            print(\"Model loaded succesfully\")\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        label_map = {label: num for num, label in enumerate(self.actions)}\n",
    "         \n",
    "        sequences, labels = [], []\n",
    "        for action in self.actions:\n",
    "            for sequence in np.array(os.listdir(os.path.join(self.path, action))).astype(int):\n",
    "                window = []\n",
    "                for frame_num in range(self.sequence_length):\n",
    "                    res = np.load(os.path.join(self.path, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)\n",
    "                sequences.append(window)\n",
    "                labels.append(label_map[action])\n",
    "\n",
    "        X = np.array(sequences)\n",
    "        y = to_categorical(labels).astype(int)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    \n",
    "    def model_statistics(self):\n",
    "        print(self.model.summary())\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Routine(Action):\n",
    "\n",
    "    def __init__(self, action, boolean):\n",
    "        # pass in the object action\n",
    "        self.action = action\n",
    "        if boolean == True:\n",
    "            with open('routine_catalogue.pkl', 'rb') as file:\n",
    "                self.routines = pickle.load(file)\n",
    "        else:\n",
    "            self.routines = {}\n",
    "\n",
    "    def update_routines(self, new_routine):\n",
    "        self.routines = self.routines | new_routine\n",
    "\n",
    "    def get_routines(self):\n",
    "        return self.routines\n",
    "\n",
    "    def store_routine(self):\n",
    "        # Open a file and use dump()\n",
    "        with open('routine_catalogue.pkl', 'wb') as file:\n",
    "            # A new file will be created\n",
    "            pickle.dump(self.routines, file)\n",
    "\n",
    "    def add_routine(self):\n",
    "\n",
    "        boolean_3 = True\n",
    "\n",
    "        while boolean_3:\n",
    "            print(\"Enter q to quit process\\n\")\n",
    "            new_routine = str(input('Enter the name of your dance routine: \\n')).lower()\n",
    "\n",
    "            if new_routine == \"q\":\n",
    "                print(\"Terminating Process\")\n",
    "                return None\n",
    "\n",
    "            elif new_routine in sorted(self.routines):\n",
    "                print(\"A routine of this name exists\")\n",
    "            else:\n",
    "                boolean_3 = False\n",
    "\n",
    "        action_list_of_routine = []\n",
    "        routine_to_add = dict()\n",
    "\n",
    "        print(\"Actions list: \\n\")\n",
    "\n",
    "        for action_item in self.action.actions:\n",
    "            option_number = np.where(self.action.actions == action_item)[0]\n",
    "\n",
    "            print(str(option_number) + \": \" + action_item)\n",
    "\n",
    "        boolean_2 = True\n",
    "\n",
    "        while boolean_2:\n",
    "            print(\"Enter -1 to quit process\\n\")\n",
    "            number_of_actions = int(input(\"Enter how many actions you wish to add to your routine: \\n\"))\n",
    "\n",
    "            if number_of_actions == -1:\n",
    "                print(\"Terminating Process\")\n",
    "                return None\n",
    "\n",
    "            elif number_of_actions <= 2:\n",
    "                print(\"You have to enter at minimum 3 actions to make a routine\\n \")\n",
    "            else:\n",
    "                boolean_2 = False\n",
    "\n",
    "        counter = 0\n",
    "        boolean = True\n",
    "\n",
    "        while boolean:\n",
    "            print(\"\\nEnter -1 to quit process\\n\")\n",
    "            action_index = int(input(\"Enter action associted to the number to add to routine: \\n\"))\n",
    "\n",
    "            if action_index == -1:\n",
    "                print(\"Terminating Process\")\n",
    "                return None\n",
    "\n",
    "            elif action_index >= len(self.action.actions) or action_index < -1:\n",
    "                print(\"There's no action associated with this index\\n\")\n",
    "\n",
    "            else:\n",
    "                action_list_of_routine.append(self.action.actions[action_index])\n",
    "                counter += 1\n",
    "                print(\"Action: \" + self.action.actions[action_index] + \" added successfully!\")\n",
    "                if number_of_actions == counter:\n",
    "                    boolean = False\n",
    "\n",
    "        print(\"Adding your routine to catalogue....\\n\")\n",
    "        print(\"\\nHere is your dance routine: \", action_list_of_routine)\n",
    "\n",
    "        routine_to_add[new_routine] = action_list_of_routine\n",
    "\n",
    "        self.update_routines(routine_to_add)\n",
    "        self.store_routine()\n",
    "\n",
    "    def find_routine(self, captured_actions):\n",
    "        \"\"\"Takes an array of actions from user. Example format:['hop', 'jump', 'kick', 'kick']  \"\"\"\n",
    "        possible_routine_list = []\n",
    "\n",
    "        for routine in self.routines:\n",
    "            score = fuzz.ratio(captured_actions, self.routines[routine])\n",
    "            highest_score = score\n",
    "            most_similar_routine = routine\n",
    "\n",
    "            if score == 100:\n",
    "                print(\"We found the routine you just did: \", routine)\n",
    "                self.display_score(score)\n",
    "                return None\n",
    "            elif score >= 55:\n",
    "                possible_routine_list.append(routine)\n",
    "            elif score > highest_score and len(possible_routine_list) == 0:\n",
    "                highest_score = score\n",
    "                most_similar_routine = routine\n",
    "        \n",
    "        if highest_score < 20:\n",
    "            print(\"We could not detect a routine with these dance steps \")        \n",
    "            \n",
    "        elif len(possible_routine_list) == 0:\n",
    "            print(\"This is the most similar dance routine we could find: \", most_similar_routine)\n",
    "            self.get_incorrect_steps([most_similar_routine], captured_actions)\n",
    "            self.display_score(score)\n",
    "            \n",
    "        else:\n",
    "            print(\"Here are the routine(s) with similar dance steps : \", possible_routine_list)\n",
    "            self.get_incorrect_steps(possible_routine_list, captured_actions)\n",
    "            self.display_score(score)\n",
    "            \n",
    "    def get_incorrect_steps(self, possible_routines, user_routine):\n",
    "        \n",
    "        for routine in possible_routines:\n",
    "            \n",
    "            print(\"For \"+ routine + \" here are the steps you need to work on\\n\")\n",
    "            \n",
    "            routine_actions = self.routines[routine]\n",
    "            index = 0\n",
    "            \n",
    "            if len(routine_actions) < len(user_routine):\n",
    "                for i in range(len(routine_actions)):\n",
    "                    if routine_actions[i] != user_routine[i]:\n",
    "                        print(\"At dance step \"+ str(i+1) + \" of dance routine \" + routine +\".\\n\")\n",
    "                        print(\"You did \"+ user_routine[i]+ \" the correct move should had been \" + routine_actions[i]+\"\\n\")\n",
    "                        index = i\n",
    "                print(\"Here are some actions in your performace we found are not in the routine: \")       \n",
    "                for i in range(index, len(user_routine)):\n",
    "                    print(user_routine[i])\n",
    "                print(\"\\n\")\n",
    "                    \n",
    "            elif len(user_routine) < len(routine_actions):\n",
    "                for i in range(len(user_routine)):\n",
    "                    if routine_actions[i] != user_routine[i]:\n",
    "                        print(\"At dance step \"+ str(i+1) + \" of dance routine \" + routine +\".\\n\")\n",
    "                        print(\"You did \"+ user_routine[i]+ \" the correct move should had been \" + routine_actions[i]+\"\\n\")\n",
    "                        index = i\n",
    "                print(\"There are a few actions in your performace we found you are missing from your routine: \")       \n",
    "                for i in range(index, len(routine_actions)):\n",
    "                    print(routine_actions[i])\n",
    "                print(\"\\n\")\n",
    "                \n",
    "            else:\n",
    "                for i in range(len(user_routine)):\n",
    "                    if routine_actions[i] != user_routine[i]:\n",
    "                        print(\"At dance step \"+ str(i+1) + \" of dance routine \" + routine +\".\\n\")\n",
    "                        print(\"You did \"+ user_routine[i]+ \" the correct move should had been \" + routine_actions[i]+\"\\n\")\n",
    "                \n",
    "    def display_score(self, score):\n",
    "        \n",
    "        if score == 100:\n",
    "            print(\"You scored a perfect 100! You are a dancing prodigy!\")   \n",
    "        elif 70 <= score <= 99:\n",
    "            print(\"Brilliant! You are close to perfection. You scored: \"+ str(score)+\"\\n\")\n",
    "        elif 40 <= score <= 69:\n",
    "            print(\"You need to practice more. You scored \" + str(score)+\"\\n\")\n",
    "        elif score <= 39:\n",
    "             print(\"At least you have personality. You scored \" + str(score)+\"\\n\")\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "659d430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = [(245, 117, 16), (117, 245, 16), (16, 117, 245), (19, 17, 245), (190, 117, 245), (190, 117, 245),\n",
    "          (190, 117, 245), (190, 117, 245), (190, 117, 245), (190, 117, 245)]\n",
    "\n",
    "\n",
    "def prob_viz(res, actions, input_frame):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0, 60 + num * 40), (int(prob * 100), 90 + num * 40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85 + num * 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "    return output_frame\n",
    "\n",
    "\n",
    "\n",
    "def go_live(model,actions,routine):\n",
    "    sequence = []\n",
    "    dance_moves = []\n",
    "    threshold = 0.5\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Set mediapipe model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "            # Draw landmarks\n",
    "            draw_styled_landmarks(image, results)\n",
    "\n",
    "            # 2. Prediction logic\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence.append(keypoints)\n",
    "            sequence = sequence[-30:]\n",
    "\n",
    "            if results.pose_landmarks is None:\n",
    "                cv2.putText(image, 'Please have your whole', (60, 200),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'body in frame', (60, 250),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "\n",
    "            else:\n",
    "\n",
    "#                 for data_point in results.pose_landmarks.landmark:\n",
    "#                     if data_point.visibility < 0.5:\n",
    "#                         cv2.putText(image, \"Having a hard time detecting you\", (60, 300),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1, (35, 200, 55), 4, cv2.LINE_AA)\n",
    "#                         cv2.putText(image, 'Area needs to be well lit', (60, 350),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1, (35, 200, 55), 4, cv2.LINE_AA)\n",
    "\n",
    "                if len(sequence) == 30:\n",
    "                    res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "\n",
    "                    if actions[np.argmax(res)] == \"stop_capturing_movement\" :\n",
    "                        routine.find_routine(dance_moves)                        \n",
    "                        cv2.putText(image, \"Capturing has stopped\", (60, 300),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (35, 200, 55), 4, cv2.LINE_AA)\n",
    "                    else:\n",
    "\n",
    "                        # 3. Viz logic\n",
    "                        if res[np.argmax(res)] > threshold:\n",
    "                            if len(dance_moves) > 0:\n",
    "                                if actions[np.argmax(res)] != dance_moves[-1]:\n",
    "                                    dance_moves.append(actions[np.argmax(res)])\n",
    "                            else:\n",
    "                                dance_moves.append(actions[np.argmax(res)])\n",
    "                                routine.find_routine(dance_moves)\n",
    "\n",
    "                        if len(dance_moves) > 5:\n",
    "                            dance_moves = dance_moves[-5:]\n",
    "\n",
    "                        # Viz probabilities\n",
    "#                         image = prob_viz(res, actions, image)\n",
    "\n",
    "                    cv2.rectangle(image, (0, 0), (640, 40), (245, 117, 16), -1)\n",
    "                    cv2.putText(image,\n",
    "                                ' '.join(dance_moves),\n",
    "                                (3, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.6,\n",
    "                                (255, 255, 255),\n",
    "                                2,\n",
    "                                cv2.LINE_AA)\n",
    "\n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "            # Break gracefully\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa0356b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba1db332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_000.mp4\n",
      "this is video number: 0\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_001.mp4\n",
      "this is video number: 1\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_002.mp4\n",
      "this is video number: 2\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_003.mp4\n",
      "this is video number: 3\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_004.mp4\n",
      "this is video number: 4\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_005.mp4\n",
      "this is video number: 5\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_006.mp4\n",
      "this is video number: 6\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_007.mp4\n",
      "this is video number: 7\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_008.mp4\n",
      "this is video number: 8\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_009.mp4\n",
      "this is video number: 9\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_010.mp4\n",
      "this is video number: 10\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_011.mp4\n",
      "this is video number: 11\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_012.mp4\n",
      "this is video number: 12\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_013.mp4\n",
      "this is video number: 13\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_014.mp4\n",
      "this is video number: 14\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_015.mp4\n",
      "this is video number: 15\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_016.mp4\n",
      "this is video number: 16\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_017.mp4\n",
      "this is video number: 17\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_018.mp4\n",
      "this is video number: 18\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_019.mp4\n",
      "this is video number: 19\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_020.mp4\n",
      "this is video number: 20\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_021.mp4\n",
      "this is video number: 21\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_022.mp4\n",
      "this is video number: 22\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_023.mp4\n",
      "this is video number: 23\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_024.mp4\n",
      "this is video number: 24\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_025.mp4\n",
      "this is video number: 25\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_026.mp4\n",
      "this is video number: 26\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_027.mp4\n",
      "this is video number: 27\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_028.mp4\n",
      "this is video number: 28\n",
      "this is video file: DATASET\\kick_right_leg\\kick_right_leg_029.mp4\n",
      "this is video number: 29\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_000.mp4\n",
      "this is video number: 0\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_001.mp4\n",
      "this is video number: 1\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_002.mp4\n",
      "this is video number: 2\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_003.mp4\n",
      "this is video number: 3\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_004.mp4\n",
      "this is video number: 4\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_005.mp4\n",
      "this is video number: 5\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_006.mp4\n",
      "this is video number: 6\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_007.mp4\n",
      "this is video number: 7\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_008.mp4\n",
      "this is video number: 8\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_009.mp4\n",
      "this is video number: 9\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_010.mp4\n",
      "this is video number: 10\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_011.mp4\n",
      "this is video number: 11\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_012.mp4\n",
      "this is video number: 12\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_013.mp4\n",
      "this is video number: 13\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_014.mp4\n",
      "this is video number: 14\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_015.mp4\n",
      "this is video number: 15\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_016.mp4\n",
      "this is video number: 16\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_017.mp4\n",
      "this is video number: 17\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_018.mp4\n",
      "this is video number: 18\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_019.mp4\n",
      "this is video number: 19\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_020.mp4\n",
      "this is video number: 20\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_021.mp4\n",
      "this is video number: 21\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_022.mp4\n",
      "this is video number: 22\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_023.mp4\n",
      "this is video number: 23\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_024.mp4\n",
      "this is video number: 24\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_025.mp4\n",
      "this is video number: 25\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_026.mp4\n",
      "this is video number: 26\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_027.mp4\n",
      "this is video number: 27\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_028.mp4\n",
      "this is video number: 28\n",
      "this is video file: DATASET\\point_left_hand_around_bounce_hips\\point_left_hand_around_bounce_hips_029.mp4\n",
      "this is video number: 29\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_000.mp4\n",
      "this is video number: 0\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_001.mp4\n",
      "this is video number: 1\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_002.mp4\n",
      "this is video number: 2\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_003.mp4\n",
      "this is video number: 3\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_004.mp4\n",
      "this is video number: 4\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_005.mp4\n",
      "this is video number: 5\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_006.mp4\n",
      "this is video number: 6\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_007.mp4\n",
      "this is video number: 7\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_008.mp4\n",
      "this is video number: 8\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_009.mp4\n",
      "this is video number: 9\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_010.mp4\n",
      "this is video number: 10\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_011.mp4\n",
      "this is video number: 11\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_012.mp4\n",
      "this is video number: 12\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_013.mp4\n",
      "this is video number: 13\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_014.mp4\n",
      "this is video number: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_015.mp4\n",
      "this is video number: 15\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_016.mp4\n",
      "this is video number: 16\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_017.mp4\n",
      "this is video number: 17\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_018.mp4\n",
      "this is video number: 18\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_019.mp4\n",
      "this is video number: 19\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_020.mp4\n",
      "this is video number: 20\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_021.mp4\n",
      "this is video number: 21\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_022.mp4\n",
      "this is video number: 22\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_023.mp4\n",
      "this is video number: 23\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_024.mp4\n",
      "this is video number: 24\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_025.mp4\n",
      "this is video number: 25\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_026.mp4\n",
      "this is video number: 26\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_027.mp4\n",
      "this is video number: 27\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_028.mp4\n",
      "this is video number: 28\n",
      "this is video file: DATASET\\start_capturing_movement\\start_capturing_movement_029.mp4\n",
      "this is video number: 29\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_000.mp4\n",
      "this is video number: 0\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_001.mp4\n",
      "this is video number: 1\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_002.mp4\n",
      "this is video number: 2\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_003.mp4\n",
      "this is video number: 3\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_004.mp4\n",
      "this is video number: 4\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_005.mp4\n",
      "this is video number: 5\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_006.mp4\n",
      "this is video number: 6\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_007.mp4\n",
      "this is video number: 7\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_008.mp4\n",
      "this is video number: 8\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_009.mp4\n",
      "this is video number: 9\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_010.mp4\n",
      "this is video number: 10\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_011.mp4\n",
      "this is video number: 11\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_012.mp4\n",
      "this is video number: 12\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_013.mp4\n",
      "this is video number: 13\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_014.mp4\n",
      "this is video number: 14\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_015.mp4\n",
      "this is video number: 15\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_016.mp4\n",
      "this is video number: 16\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_017.mp4\n",
      "this is video number: 17\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_018.mp4\n",
      "this is video number: 18\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_019.mp4\n",
      "this is video number: 19\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_020.mp4\n",
      "this is video number: 20\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_021.mp4\n",
      "this is video number: 21\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_022.mp4\n",
      "this is video number: 22\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_023.mp4\n",
      "this is video number: 23\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_024.mp4\n",
      "this is video number: 24\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_025.mp4\n",
      "this is video number: 25\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_026.mp4\n",
      "this is video number: 26\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_027.mp4\n",
      "this is video number: 27\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_028.mp4\n",
      "this is video number: 28\n",
      "this is video file: DATASET\\stop_capturing_movement\\stop_capturing_movement_029.mp4\n",
      "this is video number: 29\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_000.mp4\n",
      "this is video number: 0\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_001.mp4\n",
      "this is video number: 1\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_002.mp4\n",
      "this is video number: 2\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_003.mp4\n",
      "this is video number: 3\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_004.mp4\n",
      "this is video number: 4\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_005.mp4\n",
      "this is video number: 5\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_006.mp4\n",
      "this is video number: 6\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_007.mp4\n",
      "this is video number: 7\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_008.mp4\n",
      "this is video number: 8\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_009.mp4\n",
      "this is video number: 9\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_010.mp4\n",
      "this is video number: 10\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_011.mp4\n",
      "this is video number: 11\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_012.mp4\n",
      "this is video number: 12\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_013.mp4\n",
      "this is video number: 13\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_014.mp4\n",
      "this is video number: 14\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_015.mp4\n",
      "this is video number: 15\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_016.mp4\n",
      "this is video number: 16\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_017.mp4\n",
      "this is video number: 17\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_018.mp4\n",
      "this is video number: 18\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_019.mp4\n",
      "this is video number: 19\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_020.mp4\n",
      "this is video number: 20\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_021.mp4\n",
      "this is video number: 21\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_022.mp4\n",
      "this is video number: 22\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_023.mp4\n",
      "this is video number: 23\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_024.mp4\n",
      "this is video number: 24\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_025.mp4\n",
      "this is video number: 25\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_026.mp4\n",
      "this is video number: 26\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_027.mp4\n",
      "this is video number: 27\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_028.mp4\n",
      "this is video number: 28\n",
      "this is video file: DATASET\\sweep_hands_right\\sweep_hands_right_029.mp4\n",
      "this is video number: 29\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_000.mp4\n",
      "this is video number: 0\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_001.mp4\n",
      "this is video number: 1\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_002.mp4\n",
      "this is video number: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_003.mp4\n",
      "this is video number: 3\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_004.mp4\n",
      "this is video number: 4\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_005.mp4\n",
      "this is video number: 5\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_006.mp4\n",
      "this is video number: 6\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_007.mp4\n",
      "this is video number: 7\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_008.mp4\n",
      "this is video number: 8\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_009.mp4\n",
      "this is video number: 9\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_010.mp4\n",
      "this is video number: 10\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_011.mp4\n",
      "this is video number: 11\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_012.mp4\n",
      "this is video number: 12\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_013.mp4\n",
      "this is video number: 13\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_014.mp4\n",
      "this is video number: 14\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_015.mp4\n",
      "this is video number: 15\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_016.mp4\n",
      "this is video number: 16\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_017.mp4\n",
      "this is video number: 17\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_018.mp4\n",
      "this is video number: 18\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_019.mp4\n",
      "this is video number: 19\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_020.mp4\n",
      "this is video number: 20\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_021.mp4\n",
      "this is video number: 21\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_022.mp4\n",
      "this is video number: 22\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_023.mp4\n",
      "this is video number: 23\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_024.mp4\n",
      "this is video number: 24\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_025.mp4\n",
      "this is video number: 25\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_026.mp4\n",
      "this is video number: 26\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_027.mp4\n",
      "this is video number: 27\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_028.mp4\n",
      "this is video number: 28\n",
      "this is video file: DATASET\\turn_180_around_fist_up_sway_hips\\turn_180_around_fist_up_sway_hips_029.mp4\n",
      "this is video number: 29\n"
     ]
    }
   ],
   "source": [
    "dataset.collect_video_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5115e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = Action(Video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7df6c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kick_right_leg', 'point_left_hand_around_bounce_hips',\n",
       "       'start_capturing_movement', 'stop_capturing_movement',\n",
       "       'sweep_hands_right', 'turn_180_around_fist_up_sway_hips'],\n",
       "      dtype='<U34')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b89f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will need to capture this action 30 times\n",
      "\n",
      "Enter q to quit\n",
      "\n",
      "Make sure the name of action is at least  3 characters\n",
      "\n",
      "Enter the name of your dance action, the action has to be short to be captured: q\n",
      "Process terminated\n"
     ]
    }
   ],
   "source": [
    "action_list.add_new_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9dd3d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "dthot = KerasModel(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddfa9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "6/6 [==============================] - 2s 22ms/step - loss: 1.7657 - categorical_accuracy: 0.1345\n",
      "Epoch 2/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.4329 - categorical_accuracy: 0.3918\n",
      "Epoch 3/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6585 - categorical_accuracy: 0.7193\n",
      "Epoch 4/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.4775 - categorical_accuracy: 0.6374\n",
      "Epoch 5/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6378 - categorical_accuracy: 0.7953\n",
      "Epoch 6/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5314 - categorical_accuracy: 0.8830\n",
      "Epoch 7/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4019 - categorical_accuracy: 0.9006\n",
      "Epoch 8/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2572 - categorical_accuracy: 0.9181\n",
      "Epoch 9/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1508 - categorical_accuracy: 0.9591\n",
      "Epoch 10/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1865 - categorical_accuracy: 0.9532\n",
      "Epoch 11/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7112 - categorical_accuracy: 0.7661\n",
      "Epoch 12/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8458 - categorical_accuracy: 0.7251\n",
      "Epoch 13/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8424 - categorical_accuracy: 0.8363\n",
      "Epoch 14/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6893 - categorical_accuracy: 0.7836\n",
      "Epoch 15/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5678 - categorical_accuracy: 0.9181\n",
      "Epoch 16/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.4291 - categorical_accuracy: 0.8830\n",
      "Epoch 17/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.9109 - categorical_accuracy: 0.8772\n",
      "Epoch 18/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.4728 - categorical_accuracy: 0.9766\n",
      "Epoch 19/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3160 - categorical_accuracy: 0.9181\n",
      "Epoch 20/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.1723 - categorical_accuracy: 0.6140\n",
      "Epoch 21/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.2932 - categorical_accuracy: 0.5205\n",
      "Epoch 22/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.2031 - categorical_accuracy: 0.4561\n",
      "Epoch 23/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1074 - categorical_accuracy: 0.6374\n",
      "Epoch 24/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.9200 - categorical_accuracy: 0.6608\n",
      "Epoch 25/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0814 - categorical_accuracy: 0.7251\n",
      "Epoch 26/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6865 - categorical_accuracy: 0.7544\n",
      "Epoch 27/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.9770 - categorical_accuracy: 0.6433\n",
      "Epoch 28/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.4311 - categorical_accuracy: 0.4327\n",
      "Epoch 29/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.3033 - categorical_accuracy: 0.5146\n",
      "Epoch 30/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0166 - categorical_accuracy: 0.6199\n",
      "Epoch 31/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0588 - categorical_accuracy: 0.7251\n",
      "Epoch 32/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8285 - categorical_accuracy: 0.7661\n",
      "Epoch 33/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.9835 - categorical_accuracy: 0.7193\n",
      "Epoch 34/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.9364 - categorical_accuracy: 0.6959\n",
      "Epoch 35/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.2447 - categorical_accuracy: 0.5263\n",
      "Epoch 36/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1694 - categorical_accuracy: 0.5556\n",
      "Epoch 37/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8603 - categorical_accuracy: 0.7661\n",
      "Epoch 38/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6069 - categorical_accuracy: 0.8129\n",
      "Epoch 39/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.4385 - categorical_accuracy: 0.8480\n",
      "Epoch 40/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2507 - categorical_accuracy: 0.9649\n",
      "Epoch 41/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7646 - categorical_accuracy: 0.9181\n",
      "Epoch 42/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5237 - categorical_accuracy: 0.7953\n",
      "Epoch 43/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4471 - categorical_accuracy: 0.7895\n",
      "Epoch 44/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3969 - categorical_accuracy: 0.8070\n",
      "Epoch 45/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3720 - categorical_accuracy: 0.8070\n",
      "Epoch 46/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3071 - categorical_accuracy: 0.8187\n",
      "Epoch 47/80\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.3618 - categorical_accuracy: 0.9298\n",
      "Epoch 48/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8748 - categorical_accuracy: 0.8304\n",
      "Epoch 49/80\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9541 - categorical_accuracy: 0.6725\n",
      "Epoch 50/80\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9298 - categorical_accuracy: 0.6199\n",
      "Epoch 51/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8108 - categorical_accuracy: 0.6842\n",
      "Epoch 52/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6902 - categorical_accuracy: 0.6784\n",
      "Epoch 53/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5798 - categorical_accuracy: 0.7953\n",
      "Epoch 54/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5145 - categorical_accuracy: 0.8246\n",
      "Epoch 55/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4404 - categorical_accuracy: 0.9532\n",
      "Epoch 56/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3827 - categorical_accuracy: 0.9298\n",
      "Epoch 57/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3438 - categorical_accuracy: 0.8655\n",
      "Epoch 58/80\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3033 - categorical_accuracy: 0.8713\n",
      "Epoch 59/80\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2943 - categorical_accuracy: 0.9123\n",
      "Epoch 60/80\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1747 - categorical_accuracy: 0.9532\n",
      "Epoch 61/80\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1028 - categorical_accuracy: 0.9883\n",
      "Epoch 62/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0611 - categorical_accuracy: 0.9883\n",
      "Epoch 63/80\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2225 - categorical_accuracy: 0.9298\n",
      "Epoch 64/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2748 - categorical_accuracy: 0.9532\n",
      "Epoch 65/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0917 - categorical_accuracy: 0.9766\n",
      "Epoch 66/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0877 - categorical_accuracy: 0.9825\n",
      "Epoch 67/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0754 - categorical_accuracy: 0.9825\n",
      "Epoch 68/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0585 - categorical_accuracy: 0.9883\n",
      "Epoch 69/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0492 - categorical_accuracy: 0.9883\n",
      "Epoch 70/80\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0387 - categorical_accuracy: 0.9883\n",
      "Epoch 71/80\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0386 - categorical_accuracy: 0.9883\n",
      "Epoch 72/80\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0352 - categorical_accuracy: 0.9883\n",
      "Epoch 73/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0244 - categorical_accuracy: 0.9942\n",
      "Epoch 74/80\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0357 - categorical_accuracy: 0.9825\n",
      "Epoch 75/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0546 - categorical_accuracy: 0.9766\n",
      "Epoch 76/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0835 - categorical_accuracy: 0.9766\n",
      "Epoch 77/80\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0994 - categorical_accuracy: 0.9591\n",
      "Epoch 78/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0583 - categorical_accuracy: 0.9825\n",
      "Epoch 79/80\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0556 - categorical_accuracy: 0.9883\n",
      "Epoch 80/80\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1429 - categorical_accuracy: 0.9415\n"
     ]
    }
   ],
   "source": [
    "dthot.set_model(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a4b0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "routine = Routine(action_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01165809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': ['sweep_hands_right',\n",
       "  'sweep_hands_right',\n",
       "  'stop_capturing_movement',\n",
       "  'stop_capturing_movement',\n",
       "  'start_capturing_movement'],\n",
       " 'test 2': ['kick_right_leg',\n",
       "  'turn_180_around_fist_up_sway_hips',\n",
       "  'point_left_hand_around_bounce_hips']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routine.routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ea01ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the routine(s) with similar dance steps :  ['test 2']\n",
      "For test 2 here are the steps you need to work on\n",
      "\n",
      "At dance step 2 of dance routine test 2.\n",
      "\n",
      "You did point_left_hand_around_bounce_hips the correct move should had been turn_180_around_fist_up_sway_hips\n",
      "\n",
      "At dance step 3 of dance routine test 2.\n",
      "\n",
      "You did sweep_hands_right the correct move should had been point_left_hand_around_bounce_hips\n",
      "\n",
      "Here are some actions in your performace we found are not in the routine: \n",
      "sweep_hands_right\n",
      "kick\n",
      "spit\n",
      "lick\n",
      "\n",
      "\n",
      "You need to practice more. You scored 58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "routine.find_routine(['kick_right_leg', 'point_left_hand_around_bounce_hips', 'sweep_hands_right', 'kick', 'spit', 'lick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "14681968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the routine(s) with similar dance steps :  ['test 2']\n",
      "For test 2 here are the steps you need to work on\n",
      "\n",
      "At dance step 2 of dance routine test 2.\n",
      "\n",
      "You did point_left_hand_around_bounce_hips the correct move should had been turn_180_around_fist_up_sway_hips\n",
      "\n",
      "There are a few actions in your performace we found you are missing from your routine: \n",
      "turn_180_around_fist_up_sway_hips\n",
      "point_left_hand_around_bounce_hips\n",
      "\n",
      "\n",
      "Brilliant! You are close to perfection. You scored: 75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "routine.find_routine(['kick_right_leg', 'point_left_hand_around_bounce_hips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c5c2897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found the routine you just did:  test 2\n",
      "You scored a perfect 100! You are a dancing prodigy!\n"
     ]
    }
   ],
   "source": [
    "routine.find_routine(['kick_right_leg', 'turn_180_around_fist_up_sway_hips', 'point_left_hand_around_bounce_hips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e50f5e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kick_right_leg',\n",
       " 'turn_180_around_fist_up_sway_hips',\n",
       " 'point_left_hand_around_bounce_hips']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['kick_right_leg', 'turn_180_around_fist_up_sway_hips', 'point_left_hand_around_bounce_hips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c7518ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the routine(s) with similar dance steps :  ['test 2']\n",
      "For test 2 here are the steps you need to work on\n",
      "\n",
      "At dance step 1 of dance routine test 2.\n",
      "\n",
      "You did hop the correct move should had been kick_right_leg\n",
      "\n",
      "Brilliant! You are close to perfection. You scored: 91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "routine.find_routine(['hop', 'turn_180_around_fist_up_sway_hips', 'point_left_hand_around_bounce_hips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f32da2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the most similar dance routine we could find:  test 2\n",
      "For test 2 here are the steps you need to work on\n",
      "\n",
      "At dance step 1 of dance routine test 2.\n",
      "\n",
      "You did start_capturing_movement the correct move should had been kick_right_leg\n",
      "\n",
      "There are a few actions in your performace we found you are missing from your routine: \n",
      "kick_right_leg\n",
      "turn_180_around_fist_up_sway_hips\n",
      "point_left_hand_around_bounce_hips\n",
      "\n",
      "\n",
      "At least you have personality. You scored 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "go_live(dthot.model, action_list.actions, routine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list.add_new_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eb101d1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter q to quit process\n",
      "\n",
      "Enter the name of your dance routine: \n",
      "test 2\n",
      "Actions list: \n",
      "\n",
      "[0]: kick_right_leg\n",
      "[1]: point_left_hand_around_bounce_hips\n",
      "[2]: start_capturing_movement\n",
      "[3]: stop_capturing_movement\n",
      "[4]: sweep_hands_right\n",
      "[5]: turn_180_around_fist_up_sway_hips\n",
      "Enter -1 to quit process\n",
      "\n",
      "Enter how many actions you wish to add to your routine: \n",
      "0\n",
      "You have to enter at minimum 3 actions to make a routine\n",
      " \n",
      "Enter -1 to quit process\n",
      "\n",
      "Enter how many actions you wish to add to your routine: \n",
      "3\n",
      "\n",
      "Enter -1 to quit process\n",
      "\n",
      "Enter action associted to the number to add to routine: \n",
      "0\n",
      "Action: kick_right_leg added successfully!\n",
      "\n",
      "Enter -1 to quit process\n",
      "\n",
      "Enter action associted to the number to add to routine: \n",
      "5\n",
      "Action: turn_180_around_fist_up_sway_hips added successfully!\n",
      "\n",
      "Enter -1 to quit process\n",
      "\n",
      "Enter action associted to the number to add to routine: \n",
      "1\n",
      "Action: point_left_hand_around_bounce_hips added successfully!\n",
      "Adding your routine to catalogue....\n",
      "\n",
      "\n",
      "Here is your dance routine:  ['kick_right_leg', 'turn_180_around_fist_up_sway_hips', 'point_left_hand_around_bounce_hips']\n"
     ]
    }
   ],
   "source": [
    "routine.add_routine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
